## Яндекс Практикум, курс "Инженер Машинного Обучения" (2024 г.)
## Проект 2-го спринта: "Улучшение baseline-модели"
### *Выполнил: Кирилл Н., email: ibnkir@yandex.ru, бакет в S3: s3-student-mle-20240227-804436ded9*

### Краткое описание
Целью проекта является практическое освоение MLflow для мониторинга процесса обучения и логирования параметров, метрик, моделей и других артефактов, а также использование различных инструментов для улучшения моделей, включая генерацию и отбор признаков, подбор гипер-параметров. В качестве бейзлайна используется модель предсказания цен на квартиры из проекта 1-го спринта.

Основные инструменты: sklearn, catboost, MLflow, Autofeat, mlxtend, Optuna 

### Установка
В терминале перейти в папку, которая будет содержать папку проекта, и выполнить следующую последовательность команд:

git clone https://github.com/ibnkir/mle-project-sprint-2

cd ./mle-project-sprint-2

pip install -r requirements.txt

### Руководство по проекту
#### Этап 1: Развертывание MLflow и регистрация модели
Были загружены очищенные данные из проекта 1-го спринта, обучена модель и посчитана ошибка MAPE на тестовой выборке. Полученные метрики и модель были залогированы в MLflow.

Шаги:
- Развернуть MLflow, для чего в терминале перейти в папку mlflow_server и выполнить команду: sh run_mlflow_server.sh
- Выполнить код в ноутбуке ./mlflow_server/notebook_step_1.ipynb

Результаты в MLflow:
- Имя эксперимента: 'mle-project-sprint-2'
- Имя запуска: 'step_1'
- ID запуска: '22fde55afd764a32895bbbce0df32509'
- Имя модели: 'flats_price_model_sprint_2_step_1' (сохранена в папке 'models')

#### Этап 2: Проведение EDA 
Были загружены и очищены исходные данные из проекта 1-го спринта, выявлены и проанализированы различные зависимости и особенности, построены графики и таблицы. Результаты были залогированы в MLflow, включая файлы notebook_eda.ipynb с кодом и conclusions_eda.md с выводами.

Шаги:
- Выполнить код в ноутбуке ./mlflow_improvement/notebook_eda.ipynb со всеми шагами EDA
- Выполнить код в ноутбуке ./mlflow_improvement/notebook_steps_2_5.ipynb в разделе 2-го этапа для логирования результатов EDA (см. содержание со ссылками в начале ноутбука)

Результаты в MLflow:
- Имя эксперимента: 'mle-project-sprint-2'
- Имя запуска: 'step_2'
- ID запуска: 'dda6cd831cf14ed3a90b275be16cdc63'
- Ноутбук и md-файл (сохранены в папке 'eda')

#### Этап 3: Генерация признаков и обучение модели
Были сгенерированы и нормализованы числовые признаки с помощью PolynomialFeatures, QuantileTransformer, AutoFeatRegressor (трансформации автогенератора: '1+', 'log') и StandardScaler, после чего обучена и залогирована новая модель. По сравнению с 1-м этапом ошибка MAPE на тестовых данных стала меньше.

Шаги:
- Выполнить код в ноутбуке ./mlflow_improvement/notebook_steps_2_5.ipynb в разделе 3-го этапа (см. содержание со ссылками в начале ноутбука).

Результаты в MLflow:
- Имя эксперимента: 'mle-project-sprint-2'
- Имя запуска: 'step_3'
- ID запуска: '85f646eecd7047b5ac5e253aa54bcf04'
- Имя модели: 'flats_price_model_sprint_2_step_3' (сохранена в папке 'models')
- Имя автогенератора признаков: 'af_reg_sprint_2_step_3' (сохранен в папке 'encoders')

#### Этап 4: Отбор признаков и обучение новой версии модели
С помощью методов Sequential Forward Floating (SFFS) и Sequential Forward Selection (SFS) были отобраны преобразованные на предыдущем этапе признаки. Новая модель была обучена на объединенном наборе этих признаков и залогирована. Ошибка MAPE на тестовых данных снова немного уменьшилась.

Шаги:
- Выполнить код в ноутбуке ./mlflow_improvement/notebook_steps_2_5.ipynb в разделе 4-го этапа (см. содержание со ссылками в начале ноутбука).

Результаты в MLflow:
- Имя эксперимента: 'mle-project-sprint-2'
- Имя запуска: 'step_4'
- ID запуска: 'c84a7a4fe4f545fa9589a40982a1704f'
- Имя модели: 'flats_price_model_sprint_2_step_4'
- Графики и таблицы (сохранены в папке 'fs_assets')

#### Этап 5: Подбор гиперпараметров и обучение новой версии модели
Были подобраны гиперпараметры на ранее преобразованных и отобранных признаках с помощью 2-х методов: случайного поиска и байесовской оптимизации. Наилучшая метрика получилась у 1-го способа. После этого была обучена и залогирована новая модель с соответствующими лучшими параметрами. В результате ошибка стала наименьшей по сравнению со всеми предыдущими этапами.

Шаги:
- Выполнить код в ноутбуке ./mlflow_improvement/notebook_steps_2_5.ipynb в разделе 5-го этапа (см. содержание со ссылками в начале ноутбука).

Результаты в MLflow:
- Имя эксперимента: 'mle-project-sprint-2'
- Имя запуска: 'step_5'
- ID запуска: '59d04bca4276425aa0f6de46a69c868a'
- Имя модели: 'flats_price_model_sprint_2_step_5' (сохранена в папке 'models')
